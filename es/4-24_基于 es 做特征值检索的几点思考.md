# 基于 es 做特征值检索的几点思考

背景：

- 使用 es 二进制类型存储 512 维 float 类型的单位向量特征值
- 实现了 es 里面的 ScriptScorePlugin 进行特征值运算进行暴力比对

通过查找资料，找到了几种解决方案：

- LSH
- HNSW
- IVF-PQ

## 关于改进的尝试

### LSH

主要花时间实现了基于随机超平面的 LSH 方法，实现起来很简单：

- 随机生成 n 个 512 维的 hash 向量
- 使用 hash 向量与存储的向量计算余弦值，大于 0 记做 1 ，小于等于 0 记做 0 ，可以生成 n bit 的 hash 码
- 对比两个向量的 hash 码，统计相同的位数，相同的位数越多认为越相似

500 万条数据，根据上面的方法，取前 100 条，效果很差，召回率太低。

考虑到一种方案：

- 通过 hash 码，比对取前 10000 条数据
- 在对这 10000 条数据计算余弦相似度
- 取前 100 条

这种方式效果还勉强可以。

使用 LSH 的方式复杂度没有降低，还是 O(N) ，但是统计相同的位数，速度更快，需要加载的数据量更少，可以提高一定的效率。

### open distro knn

Amazon 开源的一个解决方案，对 es kibana 做了一些修改，加入了安全模块的支持等。

里面包含的 k-NN 插件，可以用于高维向量的搜索，插件的描述：

> Open Distro for Elasticsearch k-NN plugin enables users to run nearest neighbor search on billions of documents across thousands of dimensions with the same ease as running any regular Elasticsearch query. Use aggregations and filter clauses to further refine your similarity search operations. Power uses cases such as product recommendations, fraud detection, image and video search, related document search, and more.

尝试了一下在 es 官方版本中集成 k-NN 插件，会出现各种问题，使用 Open Distro 的 es 也需要配置一些安全方面的参数，有点小麻烦。

k-NN 是基于 HNSW 方式实现的，数据全部加载到内存中，考虑到硬件资源有限，没深入了解。

### 其他尝试

缩减数据量：

- 512 维的 float 数组，一条特征值就需要占用 2KB 的存储空间
- 在暴力比对的过程中，需要把数据从硬盘加载到内存，如果可以缩减数据大小，可以加快从硬盘加载数据的时间
- java 里面的 float 占用 4 个字节，没有提供半精度浮点数，这种类型
- float 在内存中的存储方式 1 bit 的符号位 8 bit 的指数位，23 bit 的底数
- 转成 FP16 格式的半精度浮点数，不太方便，这里直接把 23 bit 的底数裁剪掉 16 bit，运算的时候通过补 16 bit 的 0 ，生成 float 进行运算
- 由于使用的是单位向量，这种方式损失的精度很少，但是占用的空间缩减了 1 半

## 结论

- 这种优化没有算法的支持，能够优化的地方有限，优化的效果也有限
